Stanford NLP work ranges from basic research in computational linguistics to key applications in human language technology, and covers areas such as sentence understanding, automatic question answering, machine translation, syntactic parsing and tagging, sentiment analysis, and models of text and visual scenes, as well as applications of natural language processing to the digital humanities and computational social sciences.

A distinguishing feature of the Stanford NLP Group is effective combination of sophisticated and deep linguistic modeling and data analysis with innovative probabilistic, machine learning, and deep learning approaches to NLP. Their research has resulted in state-of-the-art technology for robust, broad-coverage natural-language processing in a number of languages. They provide a widely used, integrated NLP toolkit, Stanford CoreNLP. Particular technologies include our competition-winning coreference resolution system; a high speed, high performance neural network dependency parser; a state-of-the-art part-of-speech tagger; a competition-winning named entity recognizer; and algorithms for processing Arabic, Chinese, French, German, and Spanish text.

Stanford CoreNLP provides a set of human language technology tools. It can give the base forms of words, their parts of speech, whether they are names of companies, people, etc., normalize dates, times, and numeric quantities, mark up the structure of sentences in terms of phrases and syntactic dependencies, indicate which noun phrases refer to the same entities, indicate sentiment, extract particular or open-class relations between entity mentions, get the quotes people said, etc.